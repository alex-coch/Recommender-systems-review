{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"colab":{"name":"recommender_systems_review.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"macro-lodging"},"source":["### Обзор алгоритмов рекомендательных систем"],"id":"macro-lodging"},{"cell_type":"markdown","metadata":{"id":"metric-rings"},"source":["Несмотря на множество существующих алгоритмов, все они сводятся к нескольким базовым подходам, которые будут описаны далее. К наиболее классическим относятся алгоритмы Summary-based (неперсональные), Content-based (модели основанные на описании товара), Matrix Factorization (методы основанные на матричном разложении), Collaborative Filtering (коллаборативная фильтрация) и гибридные."],"id":"metric-rings"},{"cell_type":"markdown","metadata":{"id":"wBl74ITNdBHx"},"source":["#### Неперсонализированные рекомендации (summary-based)\n","\n","Начнем с неперсонализированных рекомендаций, поскольку они самые простые в реализации. В них потенциальный интерес пользователя определяется просто средним рейтингом.\n"],"id":"wBl74ITNdBHx"},{"cell_type":"markdown","metadata":{"id":"M5BJlB5ydPIK"},"source":[""],"id":"M5BJlB5ydPIK"},{"cell_type":"markdown","metadata":{"id":"AvPiff-CdZFl"},"source":["##### Проблема холодного старта"],"id":"AvPiff-CdZFl"},{"cell_type":"markdown","metadata":{"id":"c9RIV8jCddkq"},"source":["Холодный старт – это типичная ситуация, когда ещё не накоплено достаточное количество данных для корректной работы рекомендательной системы (например, когда товар новый или просто его очень редко покупают). Если средний рейтинг посчитан по оценкам всего трёх пользователей, такая оценка явно не будет достоверной, и пользователи это понимают. Часто в таких ситуациях рейтинги искусственно корректируют."],"id":"c9RIV8jCddkq"},{"cell_type":"markdown","metadata":{"id":"S0xYNu8Edk8m"},"source":["##### Актуальность рекомендаций"],"id":"S0xYNu8Edk8m"},{"cell_type":"markdown","metadata":{"id":"vXAhLv08eNG0"},"source":["В некоторых случаях также важно учитывать «свежесть» рекомендации. Это особенно актуально для статей или постов на форумах. Пример расчета рейтинга в журнале Hacker news:\n","![Untitled.jpg](https://hsto.org/r/w1560/webt/vc/yr/sn/vcyrsnoylizvctaq3ilbafaosbq.jpeg)"],"id":"vXAhLv08eNG0"},{"cell_type":"markdown","metadata":{"id":"XwUe9BooemIj"},"source":["где U = upvotes, D = downvotes, а P (Penalty) — дополнительная корректировка для имплементации иных бизнес-правил\n","\n","Расчет рейтинга в Reddit:\n","![image.png](https://hsto.org/r/w1560/webt/g-/zj/fg/g-zjfghqsstjvuryzd-b9c92hjk.jpeg)"],"id":"XwUe9BooemIj"},{"cell_type":"markdown","metadata":{"id":"vTd4nS6HesAr"},"source":["где U = число голосов «за», D = число голосов «против», T = время записи. Первое слагаемое оценивает «качество записи», а второе делает поправку на время."],"id":"vTd4nS6HesAr"},{"cell_type":"markdown","metadata":{"id":"aK5JOK23evr3"},"source":["#### Content-based рекомендации\n","Персональные рекомендации предполагают максимальное использование информации о самом пользователе, в первую очередь о его предыдущих покупках. Товары и услуги рекомендуются на основе знаний о них. Одним из первых появился подход content-based filtering."],"id":"aK5JOK23evr3"},{"cell_type":"markdown","metadata":{"id":"8lO5hqVSe8gz"},"source":["\n","![image.png](https://hsto.org/r/w1560/webt/ns/yf/-l/nsyf-lljlfb0r7bjrc_l3xonto0.jpeg)"],"id":"8lO5hqVSe8gz"},{"cell_type":"markdown","metadata":{"id":"SmQ-9oXIH_Pi"},"source":["В качестве меры близости двух векторов чаще всего используется косинусное расстояние.\n","![0a6136c9bd4144fabc84b53b4e0b6f49.png](https://hsto.org/r/w1560/getpro/habr/post_images/0a6/136/c9b/0a6136c9bd4144fabc84b53b4e0b6f49.png)"],"id":"SmQ-9oXIH_Pi"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"finished-accessory","executionInfo":{"status":"ok","timestamp":1629524603943,"user_tz":-240,"elapsed":2702,"user":{"displayName":"alex c","photoUrl":"","userId":"09356638707775981762"}},"outputId":"b2e4f944-a111-4e24-8dac-6dbbce737a80"},"source":["# Loading the data\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import linear_kernel\n","ds = pd.read_csv('https://raw.githubusercontent.com/alex-coch/Recommender-systems-review/main/sample-data.csv')\n","\n","# Creating a TF-IDF Vectirizer and calculate the TF-IDF score for each document's description\n","# tfidt_matrix is the matrix containing each word and its TF-IDF score\n","tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n","tfidf_matrix = tf.fit_transform(ds['description'])\n","\n","# Calculating Cosine Similarity of each item with every other item in the dataset, and the arranging\n","# them according to their similarity with item i, and storing values in results\n","cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n","results = {}\n","for idx, row in ds.iterrows():\n","    similar_indices = cosine_similarities[idx].argsort()[:-100:-1]\n","    similar_items = [(cosine_similarities[idx][i], ds['id'][i]) for i in similar_indices]\n","\n","    results[row['id']] = similar_items[1:]\n","print('done!')\n","\n","# Making a recommendation\n","def item(id):\n","    return ds.loc[ds['id'] == id]['description'].tolist()[0].split(' - ')[0]\n","\n","\n","# Just reads the results out of the dictionary.\n","# The function collects the results[] corresponding to that item_id\n","def recommend(item_id, num):\n","    print(\"Recommending \" + str(num) + \" products similar to '\" + item(item_id) + \"'...\")\n","    print(\"-------\")\n","    recs = results[item_id][:num]\n","    for rec in recs:\n","        print(\"Recommended: \" + item(rec[1]) + \" (score:\" + str(rec[0]) + \")\")\n","\n","\n","recommend(item_id=11, num=5)"],"id":"finished-accessory","execution_count":1,"outputs":[{"output_type":"stream","text":["done!\n","Recommending 5 products similar to 'Baby sunshade top'...\n","-------\n","Recommended: Sunshade hoody (score:0.21330296021085024)\n","Recommended: Baby baggies apron dress (score:0.10975311296284812)\n","Recommended: Runshade t-shirt (score:0.09988151262780731)\n","Recommended: Runshade t-shirt (score:0.09530698241688207)\n","Recommended: Runshade top (score:0.08510550093018411)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7gPvgM4ebvem"},"source":["#### Алгоритмы факторизации (Matrix Factorization)\n","Было бы здорово описать интересы пользователя более «крупными мазками». Не в формате «он любит фильмы X, Y и Z», а в формате «он любит современные российские комедии». Помимо того, что это увеличит обобщаемость модели, это еще решит проблему большой размерности данных — ведь интересы будут описываться не вектором товаров, а существенно меньшим вектором предпочтений."],"id":"7gPvgM4ebvem"},{"cell_type":"markdown","metadata":{"id":"RcbSP6QmbzkA"},"source":["Такие подходы еще называют спектральным разложением или высокочастотной фильтрацией (поскольку мы убираем шум и оставляем полезный сигнал). В алгебре существует много различных разложений матриц, и одно из наиболее часто используемых называется SVD-разложением (singular value decomposition). В основе метода — разложение исходной матрицы рейтингов ® в произведение 3 матриц:"],"id":"RcbSP6QmbzkA"},{"cell_type":"markdown","metadata":{"id":"UaPmOMQub3Lq"},"source":["![2c83c9208eb951771aefef402c22b6f2.svg](https://hsto.org/getpro/habr/formulas/2c8/3c9/208/2c83c9208eb951771aefef402c22b6f2.svg), где размеры матриц ![dd9b62bd17c350ddcc2771beb9f6c400.svg](https://hsto.org/getpro/habr/formulas/dd9/b62/bd1/dd9b62bd17c350ddcc2771beb9f6c400.svg)"],"id":"UaPmOMQub3Lq"},{"cell_type":"markdown","metadata":{"id":"juszqwV2b7fE"},"source":["Применяя данное разложение к нашей матрице предпочтений, мы получаем две матрицы факторов (сокращенных описаний):\n","U — компактное описание предпочтений пользователя,\n","S — компактное описание характеристик продукта."],"id":"juszqwV2b7fE"},{"cell_type":"markdown","metadata":{"id":"rxX6dsnacD3P"},"source":["Для того, чтобы получить приближение матрицы предпочтений достаточно перемножить матрицы факторов. Сделав это получим оценку рейтинга для всех пар клиент-продукт."],"id":"rxX6dsnacD3P"},{"cell_type":"markdown","metadata":{"id":"WIvDOQXVcIQ9"},"source":["[Пример реализации алгоритма Matrix Factorization](https://colab.research.google.com/drive/1uCK_qUqrGQ_MYGIisF_xpuzarjEHMGJy)"],"id":"WIvDOQXVcIQ9"},{"cell_type":"markdown","metadata":{"id":"ZRiUH4GLkG4n"},"source":["#### Collaborative Filtering (коллаборативная фильтрация)\n","В рамках подхода рекомендации генерируются на основании интересов других похожих пользователей (User-based вариант). Такие рекомендации являются результатом «коллаборации» множества пользователей.\n","Классическая реализация алгоритма основана на принципе k ближайших соседей, где для каждого пользователя ищем k наиболее похожих на него (в терминах предпочтений) и дополняем информацию о пользователе известными данными по его соседям.\n","![image.png](https://hsto.org/r/w1560/webt/al/it/fv/alitfv0yszejlvhji0agoy01amg.jpeg)"],"id":"ZRiUH4GLkG4n"},{"cell_type":"markdown","metadata":{"id":"Eeo7l2g9kxuE"},"source":["На картинке выше проиллюстрирован принцип работы метода. В матрице предпочтений желтым цветом выделен пользователь, для которого мы хотим определить оценки по новым товарам (знаки вопроса). Синим цветом выделены три его ближайших соседа.\n"],"id":"Eeo7l2g9kxuE"},{"cell_type":"markdown","metadata":{"id":"QupgjP-ClC7V"},"source":["##### Стандартизация данных (scaling)\n","Поскольку все пользователи оценивают по-разному – кто-то всем подряд пятерки ставит, а от кого-то четверки редко дождешься – перед расчетом данные лучше нормализовать, т.е. привести к единой шкале, чтобы алгоритм мог корректно сравнивать их между собой."],"id":"QupgjP-ClC7V"},{"cell_type":"markdown","metadata":{"id":"I4utpQuzlMQV"},"source":["Подход Item-based является естественной альтернативой классическому подходу User-based, описанному выше, и почти полностью его повторяет, за исключением одного момента — применяется он к транспонированной матрице предпочтений. Т.е. ищет близкие товары, а не пользователей."],"id":"I4utpQuzlMQV"},{"cell_type":"markdown","metadata":{"id":"4wP8BuCxq9UX"},"source":["[Пример реализации алгоритма Collaborative Filtering](https://colab.research.google.com/drive/1X4QC7-sR3f2P7jvxinQXDeTEUwu0SUJC)"],"id":"4wP8BuCxq9UX"},{"cell_type":"markdown","metadata":{"id":"3rsLFkthfa0s"},"source":["#### Гибридные решения (hybrid)\n","\n","Есть несколько распространенных типов комбинирования:\n","*   реализация по отдельности коллаборативных и контентных алгоритмов и объединение их предположений;\n","*   включение некоторых контентных правил в коллаборативную методику;\n","*   включение некоторых коллаборативных правил в контентную методику;\n","*   построение общей модели, включающей в себя правила обеих методик.\n","\n","\n"],"id":"3rsLFkthfa0s"},{"cell_type":"markdown","metadata":{"id":"g2syR91giByA"},"source":["Несколько стратегий объединения:\n","*   Weighting — считать средневзвешенный прогноз по нескольким оценкам;\n","*   Stacking — предсказания отдельных моделей являются входами другого (мета)классификатора, который обучается правильно взвешивать промежуточные оценки;\n","*   Switching — для разных продуктов/пользователей применять различные алгоритмы;\n","*   Mixing — вычисляются рекомендации по разным алгоритмам, а потом просто объединяются в один список."],"id":"g2syR91giByA"},{"cell_type":"markdown","metadata":{"id":"sICkDfrchSdu"},"source":["Гибридные модели рекомендации:\n","*   Машина Факторизации (Factorization Machine);\n","*   Широкие и глубокие: нейронная коллаборативная фильтрация (NCF) и Глубокие Машины Факторизации (DeepFM);\n","*   DLRM – рекомендационная модель глубокого обучения. \n"],"id":"sICkDfrchSdu"},{"cell_type":"markdown","metadata":{"id":"85GTyQOtizDW"},"source":["#### Другие подходы\n","\n","*   Ассоциативные правила (Association Rules) - если мы видим, что молоко в корзину клиент уже положил, самое время напомнить о хлебе;\n","*   RBM (restricted Bolzman Machines) - ищется наиболее компактное описание пользовательских предпочтений;\n","*   Автоэнкодеры (autoencoders) - получается некий усредненный, очищенный от шума шаблон (данные о пользователе), по которому можно оценить интерес к любому продукту;\n","*   DSSM (deep sematic similiarity models) - в роли латентных переменных здесь внутренние тензорные описания входных данных (embeddings).\n"],"id":"85GTyQOtizDW"},{"cell_type":"markdown","metadata":{"id":"FpXLm_JldyoQ"},"source":["Источники данных:\n","\n","\n","*   https://habr.com/ru/company/lanit/blog/420499/ \n","*   https://habr.com/ru/company/lanit/blog/421401/\n","*   https://grouplens.org/datasets/movielens/\n","*   https://heartbeat.fritz.ai/recommender-systems-with-python-part-i-content-based-filtering-5df4940bd831\n","*   https://heartbeat.fritz.ai/recommender-systems-with-python-part-ii-collaborative-filtering-k-nearest-neighbors-algorithm-c8dcd5fd89b2 \n","*   https://heartbeat.fritz.ai/recommender-systems-with-python-part-iii-collaborative-filtering-singular-value-decomposition-5b5dcb3f242b\n","\n","\n","\n"],"id":"FpXLm_JldyoQ"}]}